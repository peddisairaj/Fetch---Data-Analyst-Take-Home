{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91196ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section I: Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Products Data (PRODUCTS_TAKEHOME.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54234dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Products Data\n",
    "products = pd.read_csv('PRODUCTS_TAKEHOME.csv')\n",
    "\n",
    "# Function to check missing data\n",
    "def missing_summary(df, name):\n",
    "    print(f\"Missing data for {name}:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "# Products Data Exploration\n",
    "missing_summary(products, \"Products\")\n",
    "\n",
    "# Check top manufacturers\n",
    "print(\"Top 10 Manufacturers:\\n\", products['MANUFACTURER'].value_counts().head(10))\n",
    "\n",
    "# Check top categories\n",
    "print(\"Top Categories:\\n\", products['CATEGORY_1'].value_counts())\n",
    "\n",
    "# Barcode Distribution - Outlier Check\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=products['BARCODE'])\n",
    "plt.title(\"Product Barcode Distribution (Outlier Check)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Transactions Data (TRANSACTION_TAKEHOME.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c116659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load Transactions Data\n",
    "transactions = pd.read_csv('TRANSACTION_TAKEHOME.csv')\n",
    "\n",
    "# Function to check missing data\n",
    "def missing_summary(df, name):\n",
    "    print(f\"Missing data for {name}:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "# Transactions Data Exploration\n",
    "missing_summary(transactions, \"Transactions\")\n",
    "\n",
    "# Check final quantity counts (including data cleaning need)\n",
    "print(\"Final Quantity Counts:\\n\", transactions['FINAL_QUANTITY'].value_counts())\n",
    "\n",
    "# Review top Final Sale values\n",
    "print(\"Top Final Sale Values:\\n\", transactions['FINAL_SALE'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f68eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Users Data (USER_TAKEHOME.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Users Data\n",
    "users = pd.read_csv('USER_TAKEHOME.csv')\n",
    "\n",
    "# Function to check missing data\n",
    "def missing_summary(df, name):\n",
    "    print(f\"Missing data for {name}:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "# Users Data Exploration\n",
    "missing_summary(users, \"Users\")\n",
    "\n",
    "# Check most common birth dates (check for placeholder values like 1970-01-01)\n",
    "print(\"Most Common Birth Dates:\\n\", users['BIRTH_DATE'].value_counts().head(10))\n",
    "\n",
    "# Check unusual gender values\n",
    "print(\"Gender Distribution:\\n\", users['GENDER'].value_counts())\n",
    "\n",
    "# Check language distribution\n",
    "print(\"Language Distribution:\\n\", users['LANGUAGE'].value_counts())\n",
    "\n",
    "# Analyze birth year distribution for potential age segmentation\n",
    "users['BIRTH_YEAR'] = pd.to_datetime(users['BIRTH_DATE'], errors='coerce').dt.year\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(users['BIRTH_YEAR'].dropna(), bins=30, kde=True)\n",
    "plt.title(\"User Birth Year Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Products Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "products = pd.read_csv('PRODUCTS_TAKEHOME.csv')\n",
    "\n",
    "# Make a working copy to preserve the original\n",
    "products_clean = products.copy()\n",
    "\n",
    "# Fill missing categories with 'Unknown' - these are optional but help with categorization completeness\n",
    "products_clean['CATEGORY_3'] = products_clean['CATEGORY_3'].fillna('Unknown')\n",
    "products_clean['CATEGORY_4'] = products_clean['CATEGORY_4'].fillna('Unknown')\n",
    "\n",
    "# Standardize missing manufacturer and brand - for consistency in grouping and filtering\n",
    "products_clean['MANUFACTURER'] = products_clean['MANUFACTURER'].fillna('Unknown Manufacturer')\n",
    "products_clean['BRAND'] = products_clean['BRAND'].fillna('Unknown Brand')\n",
    "\n",
    "# Replace 'PLACEHOLDER MANUFACTURER' with 'Unknown Manufacturer' to remove placeholder noise\n",
    "products_clean['MANUFACTURER'] = products_clean['MANUFACTURER'].replace('PLACEHOLDER MANUFACTURER', 'Unknown Manufacturer')\n",
    "\n",
    "# Drop products with missing barcodes - these cannot be linked to transactions\n",
    "products_clean = products_clean.dropna(subset=['BARCODE'])\n",
    "\n",
    "# Identify barcode length to check for unrealistic (too long) barcodes\n",
    "products_clean['BARCODE_LENGTH'] = products_clean['BARCODE'].astype(str).apply(len)\n",
    "\n",
    "# Flag products with barcodes longer than 15 digits as potential outliers\n",
    "products_clean['BARCODE_FLAG'] = products_clean['BARCODE_LENGTH'].apply(lambda x: 'OUTLIER' if x > 15 else 'OK')\n",
    "\n",
    "# Drop the temporary BARCODE_LENGTH column - no longer needed\n",
    "products_clean = products_clean.drop(columns=['BARCODE_LENGTH'])\n",
    "\n",
    "# Summary statistics\n",
    "original_count = len(products)\n",
    "cleaned_count = len(products_clean)\n",
    "placeholder_count = (products['MANUFACTURER'] == 'PLACEHOLDER MANUFACTURER').sum()\n",
    "unknown_manufacturer_count = (products_clean['MANUFACTURER'] == 'Unknown Manufacturer').sum()\n",
    "barcode_outlier_count = (products_clean['BARCODE_FLAG'] == 'OUTLIER').sum()\n",
    "\n",
    "# Create a cleanup summary dictionary\n",
    "cleanup_summary = {\n",
    "    'Original Product Count': original_count,\n",
    "    'After Cleanup Product Count': cleaned_count,\n",
    "    'Dropped Products (Missing Barcode)': original_count - cleaned_count,\n",
    "    'Replaced PLACEHOLDER MANUFACTURER': placeholder_count,\n",
    "    'Total Unknown Manufacturers': unknown_manufacturer_count,\n",
    "    'Flagged Barcode Outliers': barcode_outlier_count\n",
    "}\n",
    "\n",
    "# Display the summary\n",
    "print(\"Products Cleanup Summary:\")\n",
    "for k, v in cleanup_summary.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Transactions Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56022b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load transactions dataset\n",
    "transactions = pd.read_csv('TRANSACTION_TAKEHOME.csv')\n",
    "\n",
    "# Make a working copy to preserve the original\n",
    "transactions_clean = transactions.copy()\n",
    "\n",
    "# Convert FINAL_QUANTITY to numeric, replacing 'zero' with 0\n",
    "transactions_clean['FINAL_QUANTITY'] = transactions_clean['FINAL_QUANTITY'].replace('zero', 0).astype(float)\n",
    "\n",
    "# Identify transactions with missing barcodes - these may be non-scanned items (like produce or services)\n",
    "transactions_clean['MISSING_BARCODE'] = transactions_clean['BARCODE'].isnull()\n",
    "\n",
    "# Create a flag for transactions with missing or blank FINAL_SALE\n",
    "transactions_clean['FINAL_SALE_FLAG'] = transactions_clean['FINAL_SALE'].apply(lambda x: 'MISSING' if pd.isnull(x) or x.strip() == '' else 'OK')\n",
    "\n",
    "# Convert dates to datetime format to enable proper analysis\n",
    "transactions_clean['PURCHASE_DATE'] = pd.to_datetime(transactions_clean['PURCHASE_DATE'], errors='coerce')\n",
    "transactions_clean['SCAN_DATE'] = pd.to_datetime(transactions_clean['SCAN_DATE'], errors='coerce')\n",
    "\n",
    "# Summary Statistics\n",
    "original_count = len(transactions)\n",
    "missing_barcode_count = transactions_clean['MISSING_BARCODE'].sum()\n",
    "missing_sale_count = (transactions_clean['FINAL_SALE_FLAG'] == 'MISSING').sum()\n",
    "\n",
    "# Create a cleanup summary dictionary\n",
    "cleanup_summary = {\n",
    "    'Original Transaction Count': original_count,\n",
    "    'Transactions with Missing Barcodes': missing_barcode_count,\n",
    "    'Transactions with Missing or Blank Final Sale': missing_sale_count,\n",
    "}\n",
    "\n",
    "# Display the summary\n",
    "print(\"Transactions Cleanup Summary:\")\n",
    "for k, v in cleanup_summary.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Users Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b34974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load users dataset\n",
    "users = pd.read_csv('USER_TAKEHOME.csv')\n",
    "\n",
    "# Create a working copy to preserve the original data\n",
    "users_clean = users.copy()\n",
    "\n",
    "# Convert BIRTH_DATE to datetime; handle errors and leave invalid dates as NaT (missing)\n",
    "users_clean['BIRTH_DATE'] = pd.to_datetime(users_clean['BIRTH_DATE'], errors='coerce')\n",
    "\n",
    "# Fill missing STATE, LANGUAGE, and GENDER with placeholders\n",
    "users_clean['STATE'] = users_clean['STATE'].fillna('Unknown State')\n",
    "users_clean['LANGUAGE'] = users_clean['LANGUAGE'].fillna('unknown')\n",
    "users_clean['GENDER'] = users_clean['GENDER'].fillna('unknown')\n",
    "\n",
    "# Standardize GENDER field to a controlled list\n",
    "gender_map = {\n",
    "    'female': 'female',\n",
    "    'male': 'male',\n",
    "    'transgender': 'other',\n",
    "    'non_binary': 'other',\n",
    "    'Non-Binary': 'other',\n",
    "    'prefer_not_to_say': 'prefer_not_to_say',\n",
    "    'Prefer not to say': 'prefer_not_to_say',\n",
    "    'not_listed': 'other',\n",
    "    'not_specified': 'unknown',\n",
    "    'My gender isn\\'t listed': 'other',\n",
    "    'unknown': 'unknown'\n",
    "}\n",
    "users_clean['GENDER'] = users_clean['GENDER'].map(gender_map)\n",
    "\n",
    "# Flag placeholder birth dates (assumed placeholder date is 1970-01-01)\n",
    "users_clean['PLACEHOLDER_BIRTHDATE'] = users_clean['BIRTH_DATE'].apply(\n",
    "    lambda x: 'PLACEHOLDER' if x == pd.Timestamp('1970-01-01') else 'OK'\n",
    ")\n",
    "\n",
    "# Extract birth year for future age-based segmentation\n",
    "users_clean['BIRTH_YEAR'] = users_clean['BIRTH_DATE'].dt.year\n",
    "\n",
    "# Summary Statistics and Findings\n",
    "original_count = len(users)\n",
    "missing_birth_date_count = users['BIRTH_DATE'].isnull().sum()\n",
    "missing_state_count = users['STATE'].isnull().sum()\n",
    "missing_language_count = users['LANGUAGE'].isnull().sum()\n",
    "missing_gender_count = users['GENDER'].isnull().sum()\n",
    "placeholder_birthdate_count = (users_clean['PLACEHOLDER_BIRTHDATE'] == 'PLACEHOLDER').sum()\n",
    "\n",
    "# Show Final Normalized Gender Distribution\n",
    "normalized_gender_counts = users_clean['GENDER'].value_counts()\n",
    "\n",
    "# Print Final Cleanup Summary\n",
    "print(\"Users Cleanup Summary:\")\n",
    "print(f\"Original User Count: {original_count}\")\n",
    "print(f\"Missing Birth Dates (original): {missing_birth_date_count}\")\n",
    "print(f\"Missing States (original): {missing_state_count}\")\n",
    "print(f\"Missing Languages (original): {missing_language_count}\")\n",
    "print(f\"Missing Genders (original): {missing_gender_count}\")\n",
    "print(f\"Placeholder Birth Dates (1970-01-01): {placeholder_birthdate_count}\")\n",
    "print(\"\\nNormalized Gender Distribution (After Cleanup):\")\n",
    "print(normalized_gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section II: Provide SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62643b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e87b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Data into SQLite In-Memory Database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load cleaned data into SQLite tables\n",
    "products_cleaned = pd.read_csv('PRODUCTS_TAKEHOME_CLEANED.csv')\n",
    "transactions_cleaned = pd.read_csv('TRANSACTION_TAKEHOME_CLEANED.csv')\n",
    "users_cleaned = pd.read_csv('USER_TAKEHOME_CLEANED.csv')\n",
    "\n",
    "products_cleaned.to_sql('products', conn, index=False, if_exists='replace')\n",
    "transactions_cleaned.to_sql('transactions', conn, index=False, if_exists='replace')\n",
    "users_cleaned.to_sql('users', conn, index=False, if_exists='replace')\n",
    "\n",
    "print(\"Tables loaded into SQLite:\")\n",
    "print(pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f103994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed-Ended Questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ad7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What are the top 5 brands by receipts scanned among users 21 and over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Brands by Receipts Scanned for Users 21+\n",
    "query_1 = '''\n",
    "SELECT p.BRAND, COUNT(DISTINCT t.RECEIPT_ID) AS receipt_count\n",
    "FROM transactions t\n",
    "JOIN products p ON t.BARCODE = p.BARCODE\n",
    "JOIN users u ON t.USER_ID = u.ID\n",
    "WHERE (strftime('%Y', 'now') - u.BIRTH_YEAR) >= 21\n",
    "GROUP BY p.BRAND\n",
    "ORDER BY receipt_count DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "top_brands = pd.read_sql(query_1, conn)\n",
    "\n",
    "print(\"\\nTop 5 Brands by Receipts Scanned (21+):\")\n",
    "print(top_brands)\n",
    "\n",
    "# Horizontal Bar Chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y='BRAND', x='receipt_count', data=top_brands)\n",
    "plt.title('Top 5 Brands by Receipts Scanned (21+)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc04c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What are the top 5 brands by sales among users that have had their account for at least six months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Brands by Sales for Users with 6+ Months Account Age\n",
    "query_2 = '''\n",
    "SELECT p.BRAND, SUM(CAST(t.FINAL_SALE AS FLOAT)) AS total_sales\n",
    "FROM transactions t\n",
    "JOIN products p ON t.BARCODE = p.BARCODE\n",
    "JOIN users u ON t.USER_ID = u.ID\n",
    "WHERE date('now') >= date(u.CREATED_DATE, '+6 months')\n",
    "AND t.FINAL_SALE_FLAG = 'OK'\n",
    "GROUP BY p.BRAND\n",
    "ORDER BY total_sales DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "top_sales_brands = pd.read_sql(query_2, conn)\n",
    "\n",
    "print(\"\\nTop 5 Brands by Sales (6+ Months Users):\")\n",
    "print(top_sales_brands)\n",
    "\n",
    "# Pie Chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(top_sales_brands['total_sales'], labels=top_sales_brands['BRAND'], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Top 5 Brands by Sales (6+ Months Users)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e748a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the percentage of sales in the Health & Wellness category by generation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of Health & Wellness Sales by Generation\n",
    "query_3 = '''\n",
    "WITH user_gen AS (\n",
    "    SELECT \n",
    "        ID,\n",
    "        CASE \n",
    "            WHEN BIRTH_YEAR >= 1997 THEN 'Gen Z'\n",
    "            WHEN BIRTH_YEAR BETWEEN 1981 AND 1996 THEN 'Millennials'\n",
    "            WHEN BIRTH_YEAR BETWEEN 1965 AND 1980 THEN 'Gen X'\n",
    "            ELSE 'Baby Boomers'\n",
    "        END AS generation\n",
    "    FROM users\n",
    ")\n",
    ", category_sales AS (\n",
    "    SELECT \n",
    "        g.generation,\n",
    "        SUM(CAST(t.FINAL_SALE AS FLOAT)) AS health_wellness_sales\n",
    "    FROM transactions t\n",
    "    JOIN products p ON t.BARCODE = p.BARCODE\n",
    "    JOIN user_gen g ON t.USER_ID = g.ID\n",
    "    WHERE p.CATEGORY_1 = 'Health & Wellness'\n",
    "    AND t.FINAL_SALE_FLAG = 'OK'\n",
    "    GROUP BY g.generation\n",
    ")\n",
    ", total_sales AS (\n",
    "    SELECT SUM(CAST(t.FINAL_SALE AS FLOAT)) AS total_sales\n",
    "    FROM transactions t\n",
    "    WHERE t.FINAL_SALE_FLAG = 'OK'\n",
    ")\n",
    "SELECT \n",
    "    cs.generation,\n",
    "    (cs.health_wellness_sales * 100.0 / ts.total_sales) AS health_wellness_percentage\n",
    "FROM category_sales cs, total_sales ts\n",
    "ORDER BY health_wellness_percentage DESC;\n",
    "'''\n",
    "gen_health_wellness = pd.read_sql(query_3, conn)\n",
    "\n",
    "print(\"\\nHealth & Wellness Sales by Generation:\")\n",
    "print(gen_health_wellness)\n",
    "\n",
    "# Vertical Bar Chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='generation', y='health_wellness_percentage', data=gen_health_wellness)\n",
    "plt.title('Health & Wellness Sales by Generation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d02e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open-Ended Questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640be110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Who are Fetchâ€™s power users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1773f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Power Users\n",
    "query_4 = '''\n",
    "SELECT \n",
    "    u.ID AS user_id,\n",
    "    COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts,\n",
    "    SUM(t.FINAL_QUANTITY) AS total_items_purchased,\n",
    "    SUM(CAST(t.FINAL_SALE AS FLOAT)) AS total_spent\n",
    "FROM transactions t\n",
    "JOIN users u ON t.USER_ID = u.ID\n",
    "WHERE t.FINAL_SALE_FLAG = 'OK'\n",
    "GROUP BY u.ID\n",
    "ORDER BY total_receipts DESC, total_spent DESC, total_items_purchased DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "power_users = pd.read_sql(query_4, conn)\n",
    "\n",
    "print(\"\\nFetch Power Users:\")\n",
    "print(power_users)\n",
    "\n",
    "# Scatter Plot - Total Receipts vs Total Spent\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(power_users['total_receipts'], power_users['total_spent'], color='green')\n",
    "plt.title('Top 10 Power Users - Receipts vs Spend')\n",
    "plt.xlabel('Total Receipts')\n",
    "plt.ylabel('Total Spent')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c644689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Which is the leading brand in the Dips & Salsa category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58de75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leading Brand in Dips & Salsa\n",
    "query_5 = '''\n",
    "SELECT p.BRAND, SUM(CAST(t.FINAL_SALE AS FLOAT)) AS total_sales\n",
    "FROM transactions t\n",
    "JOIN products p ON t.BARCODE = p.BARCODE\n",
    "WHERE LOWER(p.CATEGORY_3) LIKE '%dip%' OR LOWER(p.CATEGORY_3) LIKE '%salsa%'\n",
    "AND t.FINAL_SALE_FLAG = 'OK'\n",
    "GROUP BY p.BRAND\n",
    "ORDER BY total_sales DESC\n",
    "LIMIT 1;\n",
    "'''\n",
    "top_dips_brand = pd.read_sql(query_5, conn)\n",
    "\n",
    "print(\"\\nLeading Brand in Dips & Salsa:\")\n",
    "print(top_dips_brand)\n",
    "\n",
    "# Simple Text Output\n",
    "print(f\"The leading brand in Dips & Salsa is: {top_dips_brand['BRAND'][0]} with sales of ${top_dips_brand['total_sales'][0]:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. At what percent has Fetch grown year over year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year-over-Year Growth (Based on User Account Creation Date)\n",
    "\n",
    "# Ensure dates in users table are correctly formatted in SQLite (done during initial load)\n",
    "query_6 = '''\n",
    "WITH yearly_users AS (\n",
    "    SELECT \n",
    "        strftime('%Y', CREATED_DATE) AS year,\n",
    "        COUNT(*) AS user_count\n",
    "    FROM users\n",
    "    WHERE CREATED_DATE IS NOT NULL\n",
    "    GROUP BY year\n",
    ")\n",
    ", yoy_growth AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        user_count,\n",
    "        LAG(user_count) OVER (ORDER BY year) AS previous_year_user_count,\n",
    "        CASE \n",
    "            WHEN LAG(user_count) OVER (ORDER BY year) IS NOT NULL\n",
    "            THEN (user_count - LAG(user_count) OVER (ORDER BY year)) * 100.0 / LAG(user_count) OVER (ORDER BY year)\n",
    "            ELSE NULL\n",
    "        END AS yoy_growth_percent\n",
    "    FROM yearly_users\n",
    ")\n",
    "SELECT * FROM yoy_growth;\n",
    "'''\n",
    "\n",
    "yoy_growth = pd.read_sql(query_6, conn)\n",
    "\n",
    "print(\"\\nYear-over-Year User Growth (Based on Account Creation Date):\")\n",
    "print(yoy_growth)\n",
    "\n",
    "# Line Chart for YoY Growth\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(yoy_growth['year'], yoy_growth['yoy_growth_percent'], marker='o', linestyle='-', color='purple')\n",
    "plt.title('Year-over-Year User Growth (Based on Account Creation Date)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('YoY Growth (%)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
